# Gemini3 Hybrid RAG Agent è©•ä¾¡ãƒ»æ”¹å–„ææ¡ˆæ›¸

---

## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
ã€Œè‡ªå¾‹å‹ RAG ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã€çµ±åˆç®¡ç†ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚

ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§æ›¸ã‹ã‚Œã¦ãŠã‚ŠGithubã§å…¨ã‚½ãƒ¼ã‚¹ã‚’å…¬é–‹ä¸­ã€‚
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªã‚‰ãŒã€Œè€ƒãˆã‚‹ï¼ˆReasoningï¼‰ã€ã¨ã€Œè¡Œå‹•ã™ã‚‹ï¼ˆActingï¼‰ã€ã‚’CoTã§ãƒ«ãƒ¼ãƒ—
ã€€ï¼ˆReAct + Reflectionï¼‰ + Qdrantã®é«˜é€Ÿãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
[ReAct]ï¼šè‡ªå¾‹çš„ã«æ¤œç´¢
ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–
ã€€ãƒ»CoTã®ãƒ«ãƒ¼ãƒ—
ã€€ãƒ»Hybrid RAG (Dense + Sparse)ã®æ¤œç´¢
ãƒ»ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒå®Ÿè£…
ãƒ»Gemini 3ä¸–ä»£å¯¾å¿œï¼‰ã§ã™ã€‚
[]Reflection]ï¼š
ãƒ»è‡ªå·±è©•ä¾¡çµæœã«åŸºã¥ãã€æœ€çµ‚å›ç­” (Final Answer) ã‚’æŠ½å‡ºï¼šè‡ªå·±çœå¯Ÿ
ãƒ»å›ç­”ã‚’ä½œæˆã—ãŸå¾Œã€å³åº§ã«å‡ºåŠ›ã›ãšã€Œè‡ªå·±è©•ä¾¡ã€ãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œã—ã€å›ç­”ã®å“è³ªã‚’å‘ä¸Šã€‚
ãƒ»æ¤œç´¢çµæœã¨ã®æ•´åˆæ€§ã‚„ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è‡ªã‚‰æ‰¹è©•ã—ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¹»è¦šï¼‰ã‚„èª¤ã‚Šã‚’ä¿®æ­£ã—ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å›ç­”ã—ã¾ã™ã€‚
Streamlitãƒ™ãƒ¼ã‚¹ã®UIã‚’é€šã˜ã¦ã€ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‹ã‚‰ã€Qdrant ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã€
ãã—ã¦é«˜åº¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯¾è©±ã¾ã§ã€RAG ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’ä¸€æ°—é€šè²«ã§ç®¡ç†ãƒ»é‹ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

GitHub:
https://github.com/nakashima2toshio/gemini_agent_rag



ReAct: è‡ªå¾‹çš„ã«æ¤œç´¢
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªã‚‰ãŒã€Œè€ƒãˆã‚‹ï¼ˆReasoningï¼‰ã€ã¨ã€Œè¡Œå‹•ã™ã‚‹ï¼ˆActingï¼‰ã€ã‚’CoTã§ãƒ«ãƒ¼ãƒ—
Router & Multi-turn æˆ¦ç•¥ã§ï¼ˆThoughtï¼‰ â†’ ï¼ˆActionï¼‰ â†’ ï¼ˆObservationï¼‰ ã®ãƒ«ãƒ¼ãƒ—ãŒæ˜ç¢º



---

## 2. ç¾çŠ¶è©•ä¾¡

### 2.1 è‰¯ã„ç‚¹ï¼ˆè©•ä¾¡ã§ãã‚‹ãƒã‚¤ãƒ³ãƒˆï¼‰

#### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ
- **ReActãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¡ç”¨**: Thought â†’ Action â†’ Observation ã®ãƒ«ãƒ¼ãƒ—ãŒæ˜ç¢º
- **æ‰‹å‹•Function Calling**: `enable_automatic_function_calling=False` ã«ã‚ˆã‚‹åˆ¶å¾¡ã¯å­¦ç¿’ãƒ»ãƒ‡ãƒãƒƒã‚°ã«æœ€é©
- **Mermaidã«ã‚ˆã‚‹å¯è¦–åŒ–**: å‡¦ç†ãƒ•ãƒ­ãƒ¼å›³ãŒåˆ†ã‹ã‚Šã‚„ã™ã„

```mermaid
graph TD
    A[User] --> B[Agent]
    B --> C[Thought]
    C --> D{Need Tool}
    D -- Yes --> E[ToolCall]
    D -- No --> F[Answer]
    E --> G[RAG Tool]
    G --> H[Qdrant]
    H --> G
    G --> B
    B --> F
    F --> A
```

#### å®Ÿè£…é¢
- **ã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**: ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­–ã¨ã—ã¦ `RAG_SCORE_THRESHOLD` ã‚’å®Ÿè£…
- **è¨­å®šã®å¤–éƒ¨åŒ–**: `config.py` ã«ã‚ˆã‚‹é–¾å€¤ãƒ»ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã®ç®¡ç†
- **ãƒ­ã‚°æ©Ÿèƒ½**: `logs/agent_chat.log` ã¸ã®å¯¾è©±å±¥æ­´ä¿å­˜
- **CoTå¯è¦–åŒ–**: æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã®è‰²ä»˜ãè¡¨ç¤º

#### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†
- **ToDoãƒªã‚¹ãƒˆã«ã‚ˆã‚‹æ®µéšçš„é–‹ç™º**: å„ªå…ˆåº¦ã¨çŠ¶æ…‹ãŒæ˜ç¢º
- **Phaseç®¡ç†**: æ©Ÿèƒ½ã‚’æ®µéšçš„ã«ãƒªãƒªãƒ¼ã‚¹

### 2.2 èª²é¡Œãƒ»æ”¹å–„ãŒå¿…è¦ãªç‚¹

#### è©•ä¾¡æ©Ÿèƒ½ã®æ¬ å¦‚ï¼ˆæœ€é‡è¦ï¼‰
ã€Œè©•ä¾¡ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã¨è¬³ã£ã¦ã„ã‚‹ãŒã€**è©•ä¾¡ã®ãŸã‚ã®ä»•çµ„ã¿**ãŒä¸è¶³ã—ã¦ã„ã‚‹ã€‚

- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã®å®šç¾©ãŒãªã„
- ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦ã®æ¸¬å®šæ‰‹æ®µãŒãªã„
- æ¤œç´¢ç²¾åº¦ï¼ˆRecall@K, MRRç­‰ï¼‰ã®è¨ˆæ¸¬ãŒãªã„
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®è¨˜éŒ²ãŒãªã„

#### ã‚³ãƒ¼ãƒ‰å“è³ª
- `print` æ–‡ã¨ `logger` ãŒæ··åœ¨
- å‹ãƒ’ãƒ³ãƒˆãŒä¸å®Œå…¨
- ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å­˜åœ¨ãƒã‚§ãƒƒã‚¯ãŒä¸ååˆ†

#### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…·ä½“çš„ãªå†…å®¹ãŒæœªè¨˜è¼‰
- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ä¾‹ãŒãªã„

---

## 3. æ”¹å–„ææ¡ˆ

### 3.1 ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã®æ‹¡å¼µ

```
gemini3_rag_agent/
â”œâ”€â”€ agent_main.py
â”œâ”€â”€ agent_tools.py
â”œâ”€â”€ config.py
â”œâ”€â”€ logs/
â”œâ”€â”€ ui/
â”œâ”€â”€ eval/                    # ã€è¿½åŠ ã€‘è©•ä¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cases.json      # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©
â”‚   â”œâ”€â”€ evaluator.py         # è‡ªå‹•è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯
â”‚   â”œâ”€â”€ metrics.py           # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
â”‚   â””â”€â”€ report_generator.py  # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
â”œâ”€â”€ data/                    # ã€è¿½åŠ ã€‘ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
â”‚   â””â”€â”€ sample_documents/
â”œâ”€â”€ tests/                   # ã€è¿½åŠ ã€‘å˜ä½“ãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ test_agent_tools.py
â”‚   â””â”€â”€ test_routing.py
â””â”€â”€ scripts/                 # ã€è¿½åŠ ã€‘ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    â”œâ”€â”€ setup_qdrant.py      # QdrantåˆæœŸåŒ–
    â””â”€â”€ ingest_documents.py  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæŠ•å…¥
```

### 3.2 è©•ä¾¡æŒ‡æ¨™ã®å®šç¾©

| æŒ‡æ¨™ | èª¬æ˜ | ç›®æ¨™å€¤ |
|------|------|--------|
| **ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç²¾åº¦** | ãƒ„ãƒ¼ãƒ«ä½¿ç”¨/æœªä½¿ç”¨ã®åˆ¤æ–­ãŒæ­£ã—ã„å‰²åˆ | â‰¥ 90% |
| **ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠç²¾åº¦** | é©åˆ‡ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ãŸå‰²åˆ | â‰¥ 85% |
| **æ¤œç´¢ç²¾åº¦ (Recall@3)** | ä¸Šä½3ä»¶ã«æ­£è§£ãŒå«ã¾ã‚Œã‚‹å‰²åˆ | â‰¥ 80% |
| **ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ç‡** | æ¤œç´¢çµæœãªã—ã§å›ç­”ã‚’å‰µä½œã—ãŸå‰²åˆ | 0% |
| **å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | æ¤œç´¢å®Ÿè¡Œæ™‚é–“ | â‰¤ 500ms |

### 3.3 ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…·ä½“åŒ–

```python
SYSTEM_INSTRUCTION = """
ã‚ãªãŸã¯ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ã‚’æ¤œç´¢ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

## åˆ¤æ–­åŸºæº–
ä»¥ä¸‹ã«è©²å½“ã™ã‚‹å ´åˆã¯ `search_rag_knowledge_base` ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼š
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®ä»•æ§˜ãƒ»è¨­å®šã«é–¢ã™ã‚‹è³ªå•
- ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»æ‰‹é †æ›¸ã¸ã®å‚ç…§ãŒå¿…è¦ãªè³ªå•
- ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è§£æ±ºæ–¹æ³•
- ã€Œã€œã®ä»•æ§˜ã¯ï¼Ÿã€ã€Œã€œã®è¨­å®šå€¤ã¯ï¼Ÿã€ã¨ã„ã†å½¢å¼ã®è³ªå•

ä»¥ä¸‹ã®å ´åˆã¯ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã›ãšç›´æ¥å›ç­”ã—ã¦ãã ã•ã„ï¼š
- ä¸€èˆ¬çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°çŸ¥è­˜ï¼ˆPythonã®æ–‡æ³•ãªã©ï¼‰
- æŒ¨æ‹¶ãƒ»é›‘è«‡
- è¨ˆç®—ãƒ»å¤‰æ›
- ä¸€èˆ¬å¸¸è­˜ã§ç­”ãˆã‚‰ã‚Œã‚‹è³ªå•

## ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ
åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³:
- `internal_docs`: ç¤¾å†…æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- `company_rules`: å°±æ¥­è¦å‰‡ãƒ»ç¤¾å†…è¦å®š
- `qa_pairs`: ã‚ˆãã‚ã‚‹è³ªå•ã¨å›ç­”

è³ªå•å†…å®¹ã«æœ€ã‚‚é©åˆ‡ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

## æ¤œç´¢çµæœãŒãªã„å ´åˆ
ã€Œç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€é–¢é€£ã™ã‚‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨æ­£ç›´ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
**æ¨æ¸¬ã‚„å‰µä½œã¯çµ¶å¯¾ã«è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚**

## å›ç­”å½¢å¼
1. ã¾ãšæ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’ "Thought:" ã§å§‹ã‚ã¦èª¬æ˜
2. ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯é©åˆ‡ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å‘¼ã³å‡ºã—
3. æ¤œç´¢çµæœã«åŸºã¥ã„ã¦ç°¡æ½”ã«å›ç­”
"""
```

### 3.4 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–

```python
class RAGToolError(Exception):
    """RAGãƒ„ãƒ¼ãƒ«å›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼åŸºåº•ã‚¯ãƒ©ã‚¹"""
    pass

class QdrantConnectionError(RAGToolError):
    """Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼"""
    pass

class CollectionNotFoundError(RAGToolError):
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœªå­˜åœ¨ã‚¨ãƒ©ãƒ¼"""
    pass

class EmbeddingError(RAGToolError):
    """åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼"""
    pass
```

---

## 4. æ”¹å–„ç‰ˆã‚³ãƒ¼ãƒ‰

### 4.1 agent_tools.pyï¼ˆæ”¹å–„ç‰ˆï¼‰

```python
# agent_tools.py (Improved Version)
"""
RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨ãƒ„ãƒ¼ãƒ«å®šç¾©
- æ¤œç´¢æ©Ÿèƒ½
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
"""

import os
import time
import logging
from typing import Optional, List
from dataclasses import dataclass, field

from qdrant_client import QdrantClient
from qdrant_client.http.exceptions import UnexpectedResponse
from qdrant_client_wrapper import search_collection, embed_query, QDRANT_CONFIG
from config import AgentConfig

logger = logging.getLogger(__name__)

# Initialize Client
qdrant_url = QDRANT_CONFIG.get("url", "http://localhost:6333")
client = QdrantClient(url=qdrant_url)


# ============ ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤– ============
class RAGToolError(Exception):
    """RAGãƒ„ãƒ¼ãƒ«å›ºæœ‰ã®ã‚¨ãƒ©ãƒ¼åŸºåº•ã‚¯ãƒ©ã‚¹"""
    pass

class QdrantConnectionError(RAGToolError):
    """Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼"""
    pass

class CollectionNotFoundError(RAGToolError):
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœªå­˜åœ¨ã‚¨ãƒ©ãƒ¼"""
    pass


# ============ è©•ä¾¡ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ ============
@dataclass
class SearchMetrics:
    """æ¤œç´¢çµæœã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆè©•ä¾¡ç”¨ï¼‰"""
    query: str
    collection_name: str
    latency_ms: float
    total_results: int
    filtered_results: int
    top_score: float
    scores: List[float] = field(default_factory=list)
    error: Optional[str] = None
    timestamp: str = field(default_factory=lambda: time.strftime("%Y-%m-%d %H:%M:%S"))

_search_metrics_log: List[SearchMetrics] = []

def get_search_metrics() -> List[SearchMetrics]:
    """è©•ä¾¡ç”¨: åé›†ã—ãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—"""
    return _search_metrics_log.copy()

def clear_search_metrics() -> None:
    """è©•ä¾¡ç”¨: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ã‚¯ãƒªã‚¢"""
    _search_metrics_log.clear()

def export_metrics_to_dict() -> List[dict]:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¾æ›¸å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    from dataclasses import asdict
    return [asdict(m) for m in _search_metrics_log]


# ============ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ ============
def check_qdrant_health() -> bool:
    """Qdrantã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šç¢ºèª"""
    try:
        client.get_collections()
        logger.info("Qdrant health check: OK")
        return True
    except Exception as e:
        logger.error(f"Qdrant health check failed: {e}")
        return False


# ============ ãƒ„ãƒ¼ãƒ«é–¢æ•° ============
def list_rag_collections() -> str:
    """
    åˆ©ç”¨å¯èƒ½ãªRAGã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ï¼ˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ç¨®é¡ï¼‰ã‚’å–å¾—ã—ã¾ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã©ã®ã‚ˆã†ãªçŸ¥è­˜ãŒã‚ã‚‹ã‹ã€ã€Œã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’æ•™ãˆã¦ã€ã¨è³ªå•ã—ãŸå ´åˆã«ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

    Returns:
        str: åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã®ãƒªã‚¹ãƒˆã€‚
    """
    logger.info("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—ä¸­...")
    try:
        collections_response = client.get_collections()
        collections = [c.name for c in collections_response.collections]

        if not collections:
            return "ç¾åœ¨ã€åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚‚è¡¨ç¤º
        result_lines = ["åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§:"]
        for c in collections:
            try:
                info = client.get_collection(c)
                count = info.points_count
                result_lines.append(f"- {c} ({count} documents)")
            except Exception:
                result_lines.append(f"- {c}")

        logger.info(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—å®Œäº†: {len(collections)}ä»¶")
        return "\n".join(result_lines)

    except Exception as e:
        logger.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"


def search_rag_knowledge_base(
    query: str,
    collection_name: Optional[str] = None
) -> str:
    """
    Qdrantãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å°‚é–€çš„ãªçŸ¥è­˜ã‚’æ¤œç´¢ã—ã¾ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œä»•æ§˜ã€ã€Œè¨­å®šã€ã€ŒWikipediaã®çŸ¥è­˜ã€ã€Œäº‹å®Ÿç¢ºèªã€ãªã©ã€
    å¤–éƒ¨çŸ¥è­˜ãŒå¿…è¦ãªè©³ç´°ã«ã¤ã„ã¦è³ªå•ã—ãŸå ´åˆã«ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

    ä¸€èˆ¬çš„ãªæŒ¨æ‹¶ï¼ˆã€Œã“ã‚“ã«ã¡ã¯ã€ãªã©ï¼‰ã‚„ã€å˜ç´”ãªè¨ˆç®—ã€
    ä¸€èˆ¬çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ–‡æ³•è³ªå•ã«ã¯ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚

    Args:
        query: æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„è³ªå•æ–‡ã€‚
        collection_name: æ¤œç´¢å¯¾è±¡ã®Qdrantã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã€‚
                        æŒ‡å®šã—ãªã„å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚
    Returns:
        str: æ¤œç´¢ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ï¼ˆè³ªå•ã¨å›ç­”ã®ãƒšã‚¢ï¼‰ã€‚
    """
    if collection_name is None:
        collection_name = AgentConfig.RAG_DEFAULT_COLLECTION

    start_time = time.time()
    logger.info(f"RAGæ¤œç´¢ã‚’å®Ÿè¡Œ: query='{query}', collection='{collection_name}'")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
    metrics = SearchMetrics(
        query=query,
        collection_name=collection_name,
        latency_ms=0,
        total_results=0,
        filtered_results=0,
        top_score=0.0
    )

    try:
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        existing_collections = [c.name for c in client.get_collections().collections]
        if collection_name not in existing_collections:
            error_msg = f"ã‚¨ãƒ©ãƒ¼: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection_name}' ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½: {existing_collections}"
            logger.warning(error_msg)
            metrics.error = error_msg
            metrics.latency_ms = (time.time() - start_time) * 1000
            _search_metrics_log.append(metrics)
            return error_msg

        # 1. ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        query_vector = embed_query(query)

        # 2. Qdrantæ¤œç´¢å®Ÿè¡Œ
        results = search_collection(
            client=client,
            collection_name=collection_name,
            query_vector=query_vector,
            limit=AgentConfig.RAG_SEARCH_LIMIT
        )

        metrics.total_results = len(results) if results else 0

        if not results:
            metrics.latency_ms = (time.time() - start_time) * 1000
            _search_metrics_log.append(metrics)
            logger.info("æ¤œç´¢çµæœ: 0ä»¶")
            return "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"

        # 3. ã‚¹ã‚³ã‚¢åé›† & ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        scores = [res.get("score", 0.0) for res in results]
        metrics.scores = scores
        metrics.top_score = max(scores) if scores else 0.0

        # 4. çµæœã®æ•´å½¢
        formatted_results = []
        for i, res in enumerate(results, 1):
            score = res.get("score", 0.0)

            # ã‚¹ã‚³ã‚¢é–¾å€¤ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if score < AgentConfig.RAG_SCORE_THRESHOLD:
                continue

            payload = res.get("payload", {})
            q = payload.get("question", "N/A")
            a = payload.get("answer", "N/A")
            source = payload.get("source", "unknown")

            formatted_results.append(
                f"Result {i} (Score: {score:.2f}):\n"
                f"Q: {q}\n"
                f"A: {a}\n"
                f"Source: {source}"
            )

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        metrics.filtered_results = len(formatted_results)
        metrics.latency_ms = (time.time() - start_time) * 1000
        _search_metrics_log.append(metrics)

        logger.info(
            f"æ¤œç´¢å®Œäº†: {metrics.filtered_results}/{metrics.total_results} results, "
            f"top_score={metrics.top_score:.2f}, latency={metrics.latency_ms:.1f}ms"
        )

        if not formatted_results:
            return "æ¤œç´¢çµæœã¯è¦‹ã¤ã‹ã‚Šã¾ã—ãŸãŒã€é–¢é€£æ€§ã‚¹ã‚³ã‚¢ãŒä½ã„ãŸã‚æ¡ç”¨ã—ã¾ã›ã‚“ã§ã—ãŸã€‚"

        return "\n".join(formatted_results)

    except UnexpectedResponse as e:
        error_msg = f"Qdrantã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {str(e)}"
        logger.error(error_msg)
        metrics.error = error_msg
        metrics.latency_ms = (time.time() - start_time) * 1000
        _search_metrics_log.append(metrics)
        return error_msg

    except Exception as e:
        error_msg = f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logger.error(error_msg, exc_info=True)
        metrics.error = error_msg
        metrics.latency_ms = (time.time() - start_time) * 1000
        _search_metrics_log.append(metrics)
        return error_msg


# ============ ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆGemini Function Callingç”¨ï¼‰ ============
TOOLS_DEFINITION = [
    {
        "name": "list_rag_collections",
        "description": list_rag_collections.__doc__,
        "parameters": {
            "type": "object",
            "properties": {},
            "required": []
        }
    },
    {
        "name": "search_rag_knowledge_base",
        "description": search_rag_knowledge_base.__doc__,
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„è³ªå•æ–‡"
                },
                "collection_name": {
                    "type": "string",
                    "description": "æ¤œç´¢å¯¾è±¡ã®Qdrantã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰"
                }
            },
            "required": ["query"]
        }
    }
]

# ãƒ„ãƒ¼ãƒ«åã‹ã‚‰é–¢æ•°ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
TOOLS_MAP = {
    "list_rag_collections": list_rag_collections,
    "search_rag_knowledge_base": search_rag_knowledge_base,
}
```

### 4.2 config.pyï¼ˆè¿½åŠ è¨­å®šä¾‹ï¼‰

```python
# config.py (è¿½åŠ è¨­å®š)

from dataclasses import dataclass
from typing import List
import os

@dataclass
class AgentConfig:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š"""
    # RAGè¨­å®š
    RAG_DEFAULT_COLLECTION: str = "qa_pairs"
    RAG_AVAILABLE_COLLECTIONS: List[str] = None
    RAG_SCORE_THRESHOLD: float = 0.7
    RAG_SEARCH_LIMIT: int = 5

    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    MODEL_NAME: str = "gemini-2.0-flash"
    MAX_OUTPUT_TOKENS: int = 2048
    TEMPERATURE: float = 0.3

    # è©•ä¾¡è¨­å®š
    EVAL_ENABLED: bool = True
    EVAL_LOG_METRICS: bool = True

    def __post_init__(self):
        if self.RAG_AVAILABLE_COLLECTIONS is None:
            self.RAG_AVAILABLE_COLLECTIONS = [
                "qa_pairs",
                "internal_docs",
                "company_rules"
            ]

@dataclass
class PathConfig:
    """ãƒ‘ã‚¹è¨­å®š"""
    LOG_DIR: str = "logs"
    LOG_FILE: str = "agent_chat.log"
    EVAL_OUTPUT_DIR: str = "eval/results"

    def __post_init__(self):
        os.makedirs(self.LOG_DIR, exist_ok=True)
        os.makedirs(self.EVAL_OUTPUT_DIR, exist_ok=True)
```

---

## 5. è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

### 5.1 ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©ï¼ˆeval/test_cases.jsonï¼‰

```json
{
  "version": "1.0",
  "description": "Gemini3 RAG Agent è©•ä¾¡ç”¨ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹",
  "test_cases": [
    {
      "id": "TC001",
      "category": "tool_routing",
      "subcategory": "no_tool",
      "input": "ã“ã‚“ã«ã¡ã¯",
      "expected_tool_use": false,
      "expected_collection": null,
      "description": "æŒ¨æ‹¶ â†’ ãƒ„ãƒ¼ãƒ«ä¸è¦"
    },
    {
      "id": "TC002",
      "category": "tool_routing",
      "subcategory": "no_tool",
      "input": "Pythonã§ãƒªã‚¹ãƒˆã‚’ã‚½ãƒ¼ãƒˆã™ã‚‹æ–¹æ³•ã¯ï¼Ÿ",
      "expected_tool_use": false,
      "expected_collection": null,
      "description": "ä¸€èˆ¬çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°çŸ¥è­˜ â†’ ãƒ„ãƒ¼ãƒ«ä¸è¦"
    },
    {
      "id": "TC003",
      "category": "tool_routing",
      "subcategory": "no_tool",
      "input": "3 + 5 ã¯ï¼Ÿ",
      "expected_tool_use": false,
      "expected_collection": null,
      "description": "è¨ˆç®— â†’ ãƒ„ãƒ¼ãƒ«ä¸è¦"
    },
    {
      "id": "TC004",
      "category": "tool_routing",
      "subcategory": "tool_required",
      "input": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®APIä»•æ§˜ã‚’æ•™ãˆã¦",
      "expected_tool_use": true,
      "expected_collection": "internal_docs",
      "description": "ç¤¾å†…æƒ…å ± â†’ RAGå¿…é ˆ"
    },
    {
      "id": "TC005",
      "category": "tool_routing",
      "subcategory": "tool_required",
      "input": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¯ã©ã“ï¼Ÿ",
      "expected_tool_use": true,
      "expected_collection": "internal_docs",
      "description": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰æƒ…å ± â†’ RAGå¿…é ˆ"
    },
    {
      "id": "TC006",
      "category": "collection_selection",
      "subcategory": "company_rules",
      "input": "æœ‰çµ¦ä¼‘æš‡ã®ç”³è«‹æ–¹æ³•ã¯ï¼Ÿ",
      "expected_tool_use": true,
      "expected_collection": "company_rules",
      "description": "å°±æ¥­è¦å‰‡ â†’ company_rulesã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"
    },
    {
      "id": "TC007",
      "category": "collection_selection",
      "subcategory": "qa_pairs",
      "input": "ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦æ³•ã¯ï¼Ÿ",
      "expected_tool_use": true,
      "expected_collection": "qa_pairs",
      "description": "FAQ â†’ qa_pairsã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³"
    },
    {
      "id": "TC008",
      "category": "hallucination",
      "subcategory": "unknown_info",
      "input": "å­˜åœ¨ã—ãªã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ABC123ã®è¨­å®šæ–¹æ³•ã¯ï¼Ÿ",
      "expected_tool_use": true,
      "expected_behavior": "not_found_response",
      "description": "æœªçŸ¥æƒ…å ± â†’ æ¤œç´¢å¾Œã€Œè¦‹ã¤ã‹ã‚‰ãªã„ã€ã¨å›ç­”ã™ã¹ã"
    },
    {
      "id": "TC009",
      "category": "hallucination",
      "subcategory": "low_score",
      "input": "å…¨ãé–¢ä¿‚ãªã„å®‡å®™ã®è©±ã‚’ã—ã¦",
      "expected_tool_use": false,
      "expected_behavior": "direct_response",
      "description": "é–¢ä¿‚ãªã„è©±é¡Œ â†’ ãƒ„ãƒ¼ãƒ«ä¸è¦ã§ç›´æ¥å›ç­”"
    },
    {
      "id": "TC010",
      "category": "collection_listing",
      "subcategory": "list_collections",
      "input": "ã©ã®ã‚ˆã†ãªãƒŠãƒ¬ãƒƒã‚¸ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
      "expected_tool_use": true,
      "expected_tool_name": "list_rag_collections",
      "description": "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§è¦æ±‚ â†’ list_rag_collectionsãƒ„ãƒ¼ãƒ«"
    }
  ]
}
```

### 5.2 è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆeval/evaluator.pyï¼‰

```python
# eval/evaluator.py
"""
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
"""
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import logging

logger = logging.getLogger(__name__)


@dataclass
class TestCase:
    """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹å®šç¾©"""
    id: str
    category: str
    input: str
    expected_tool_use: bool
    subcategory: str = ""
    expected_collection: Optional[str] = None
    expected_tool_name: Optional[str] = None
    expected_behavior: Optional[str] = None
    expected_keywords: Optional[List[str]] = None
    description: str = ""


@dataclass
class TestResult:
    """ãƒ†ã‚¹ãƒˆçµæœ"""
    test_case_id: str
    category: str
    input: str
    actual_tool_used: bool
    actual_tool_name: Optional[str] = None
    actual_collection: Optional[str] = None
    response: str = ""
    latency_ms: float = 0.0
    top_score: float = 0.0
    passed: bool = False
    failure_reason: str = ""
    timestamp: str = ""


def load_test_cases(path: str = "eval/test_cases.json") -> List[TestCase]:
    """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’JSONã‹ã‚‰èª­ã¿è¾¼ã¿"""
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    return [TestCase(**tc) for tc in data["test_cases"]]


def evaluate_routing(test_case: TestCase, actual_tool_used: bool) -> tuple:
    """ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ¤æ–­ã®è©•ä¾¡"""
    if test_case.expected_tool_use == actual_tool_used:
        return True, ""
    else:
        return False, f"Expected tool_use={test_case.expected_tool_use}, got {actual_tool_used}"


def evaluate_collection_selection(
    test_case: TestCase,
    actual_collection: Optional[str]
) -> tuple:
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠã®è©•ä¾¡"""
    if test_case.expected_collection is None:
        return True, ""
    if test_case.expected_collection == actual_collection:
        return True, ""
    return False, f"Expected collection='{test_case.expected_collection}', got '{actual_collection}'"


def evaluate_tool_name(
    test_case: TestCase,
    actual_tool_name: Optional[str]
) -> tuple:
    """ãƒ„ãƒ¼ãƒ«åã®è©•ä¾¡"""
    if test_case.expected_tool_name is None:
        return True, ""
    if test_case.expected_tool_name == actual_tool_name:
        return True, ""
    return False, f"Expected tool='{test_case.expected_tool_name}', got '{actual_tool_name}'"


def evaluate_hallucination(
    test_case: TestCase,
    response: str,
    search_results_found: bool
) -> tuple:
    """ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡"""
    if test_case.expected_behavior != "not_found_response":
        return True, ""

    # ã€Œè¦‹ã¤ã‹ã‚‰ãªã„ã€ç³»ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯
    not_found_keywords = [
        "è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
        "æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“",
        "è©²å½“ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“",
        "é–¢é€£æ€§ã‚¹ã‚³ã‚¢ãŒä½ã„"
    ]

    if not search_results_found:
        for keyword in not_found_keywords:
            if keyword in response:
                return True, ""
        return False, "æ¤œç´¢çµæœãªã—ã§ã‚‚ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¿œç­”ã®å¯èƒ½æ€§"

    return True, ""


def run_single_test(
    test_case: TestCase,
    agent_func,  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œé–¢æ•°
    get_metrics_func  # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—é–¢æ•°
) -> TestResult:
    """å˜ä¸€ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    start_time = time.time()

    result = TestResult(
        test_case_id=test_case.id,
        category=test_case.category,
        input=test_case.input,
        actual_tool_used=False,
        timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
    )

    try:
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ
        response, tool_info = agent_func(test_case.input)

        result.response = response
        result.actual_tool_used = tool_info.get("tool_used", False)
        result.actual_tool_name = tool_info.get("tool_name")
        result.actual_collection = tool_info.get("collection_name")
        result.latency_ms = (time.time() - start_time) * 1000

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        metrics = get_metrics_func()
        if metrics:
            latest = metrics[-1]
            result.top_score = latest.top_score

        # è©•ä¾¡å®Ÿè¡Œ
        failures = []

        # ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°è©•ä¾¡
        passed, reason = evaluate_routing(test_case, result.actual_tool_used)
        if not passed:
            failures.append(reason)

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠè©•ä¾¡
        passed, reason = evaluate_collection_selection(test_case, result.actual_collection)
        if not passed:
            failures.append(reason)

        # ãƒ„ãƒ¼ãƒ«åè©•ä¾¡
        passed, reason = evaluate_tool_name(test_case, result.actual_tool_name)
        if not passed:
            failures.append(reason)

        # ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡
        search_found = result.top_score > 0
        passed, reason = evaluate_hallucination(test_case, response, search_found)
        if not passed:
            failures.append(reason)

        result.passed = len(failures) == 0
        result.failure_reason = "; ".join(failures)

    except Exception as e:
        result.failure_reason = f"Exception: {str(e)}"
        result.passed = False
        logger.error(f"Test {test_case.id} failed with exception: {e}")

    return result


def generate_report(results: List[TestResult]) -> Dict[str, Any]:
    """è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    total = len(results)
    passed = sum(1 for r in results if r.passed)

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
    by_category = {}
    for r in results:
        cat = r.category
        if cat not in by_category:
            by_category[cat] = {"total": 0, "passed": 0, "failed_ids": []}
        by_category[cat]["total"] += 1
        if r.passed:
            by_category[cat]["passed"] += 1
        else:
            by_category[cat]["failed_ids"].append(r.test_case_id)

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ç²¾åº¦è¨ˆç®—
    for cat in by_category:
        by_category[cat]["accuracy"] = (
            by_category[cat]["passed"] / by_category[cat]["total"]
            if by_category[cat]["total"] > 0 else 0
        )

    # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·çµ±è¨ˆ
    latencies = [r.latency_ms for r in results if r.latency_ms > 0]
    avg_latency = sum(latencies) / len(latencies) if latencies else 0

    return {
        "summary": {
            "total_cases": total,
            "passed": passed,
            "failed": total - passed,
            "accuracy": passed / total if total > 0 else 0,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
        },
        "by_category": by_category,
        "performance": {
            "avg_latency_ms": round(avg_latency, 2),
            "max_latency_ms": round(max(latencies), 2) if latencies else 0,
            "min_latency_ms": round(min(latencies), 2) if latencies else 0
        },
        "failed_cases": [
            {
                "id": r.test_case_id,
                "input": r.input,
                "reason": r.failure_reason
            }
            for r in results if not r.passed
        ]
    }


def save_report(report: Dict[str, Any], output_path: str = "eval/results/report.json"):
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    logger.info(f"Report saved to {output_path}")


def print_report_summary(report: Dict[str, Any]):
    """ãƒ¬ãƒãƒ¼ãƒˆã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›"""
    print("\n" + "="*60)
    print("ğŸ“Š è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ ã‚µãƒãƒªãƒ¼")
    print("="*60)

    s = report["summary"]
    print(f"\nã€å…¨ä½“çµæœã€‘")
    print(f"  ç·ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {s['total_cases']}")
    print(f"  æˆåŠŸ: {s['passed']} / å¤±æ•—: {s['failed']}")
    print(f"  ç²¾åº¦: {s['accuracy']*100:.1f}%")

    print(f"\nã€ã‚«ãƒ†ã‚´ãƒªåˆ¥ã€‘")
    for cat, data in report["by_category"].items():
        status = "âœ…" if data["accuracy"] >= 0.9 else "âš ï¸" if data["accuracy"] >= 0.7 else "âŒ"
        print(f"  {status} {cat}: {data['accuracy']*100:.1f}% ({data['passed']}/{data['total']})")

    print(f"\nã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‘")
    p = report["performance"]
    print(f"  å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {p['avg_latency_ms']}ms")
    print(f"  æœ€å¤§: {p['max_latency_ms']}ms / æœ€å°: {p['min_latency_ms']}ms")

    if report["failed_cases"]:
        print(f"\nã€å¤±æ•—ã‚±ãƒ¼ã‚¹è©³ç´°ã€‘")
        for fc in report["failed_cases"]:
            print(f"  âŒ {fc['id']}: {fc['reason']}")

    print("\n" + "="*60)
```

### 5.3 è©•ä¾¡å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆeval/run_evaluation.pyï¼‰

```python
# eval/run_evaluation.py
"""
è©•ä¾¡å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Usage: python -m eval.run_evaluation
"""
import sys
import logging
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from eval.evaluator import (
    load_test_cases,
    run_single_test,
    generate_report,
    save_report,
    print_report_summary
)
from agent_tools import get_search_metrics, clear_search_metrics

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def mock_agent_func(user_input: str) -> tuple:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œé–¢æ•°ï¼ˆå®Ÿè£…æ™‚ã«ç½®ãæ›ãˆï¼‰

    Returns:
        tuple: (response_text, tool_info_dict)
    """
    # TODO: å®Ÿéš›ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘¼ã³å‡ºã—ã«ç½®ãæ›ãˆ
    # from agent_main import run_agent_turn
    # return run_agent_turn(user_input)

    # ãƒ¢ãƒƒã‚¯å®Ÿè£…
    tool_info = {
        "tool_used": False,
        "tool_name": None,
        "collection_name": None
    }

    # ç°¡æ˜“ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°åˆ¤å®šï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    tool_keywords = ["ä»•æ§˜", "è¨­å®š", "ãƒŠãƒ¬ãƒƒã‚¸", "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³", "API", "è¦å‰‡"]
    if any(kw in user_input for kw in tool_keywords):
        tool_info["tool_used"] = True
        tool_info["tool_name"] = "search_rag_knowledge_base"
        tool_info["collection_name"] = "internal_docs"

    return f"Response to: {user_input}", tool_info


def main():
    """è©•ä¾¡ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("è©•ä¾¡é–‹å§‹")

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
    test_cases = load_test_cases("eval/test_cases.json")
    logger.info(f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {len(test_cases)}")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¯ãƒªã‚¢
    clear_search_metrics()

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = []
    for tc in test_cases:
        logger.info(f"Running: {tc.id} - {tc.description}")
        result = run_single_test(tc, mock_agent_func, get_search_metrics)
        results.append(result)

        status = "âœ…" if result.passed else "âŒ"
        logger.info(f"  {status} {tc.id}: {result.failure_reason or 'OK'}")

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    report = generate_report(results)

    # ä¿å­˜ & å‡ºåŠ›
    save_report(report)
    print_report_summary(report)

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰ï¼ˆCIç”¨ï¼‰
    if report["summary"]["accuracy"] < 0.9:
        logger.warning("ç²¾åº¦ãŒ90%æœªæº€ã§ã™")
        sys.exit(1)

    logger.info("è©•ä¾¡å®Œäº†")


if __name__ == "__main__":
    main()
```

---

## 6. Phase 3 ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### 6.1 å„ªå…ˆåº¦åˆ¥ã‚¿ã‚¹ã‚¯

| No. | é ˜åŸŸ | ã‚¿ã‚¹ã‚¯å | è©³ç´°ãƒ»ç›®çš„ | å„ªå…ˆåº¦ | å·¥æ•° |
|-----|------|----------|------------|--------|------|
| 1 | **è©•ä¾¡** | è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ | `eval/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å®Ÿè£… | **é«˜** | 2æ—¥ |
| 2 | **è©•ä¾¡** | ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ä½œæˆï¼ˆ20ä»¶ä»¥ä¸Šï¼‰ | ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ»æ¤œç´¢ç²¾åº¦ã®æ¤œè¨¼ | **é«˜** | 1æ—¥ |
| 3 | **å“è³ª** | ãƒ­ã‚®ãƒ³ã‚°çµ±ä¸€ | print â†’ logger | ä¸­ | 0.5æ—¥ |
| 4 | **å“è³ª** | å‹ãƒ’ãƒ³ãƒˆå®Œå…¨åŒ– | mypyå¯¾å¿œ | ä¸­ | 0.5æ—¥ |
| 5 | **CI/CD** | GitHub Actionsçµ±åˆ | pytest + è©•ä¾¡è‡ªå‹•å®Ÿè¡Œ | ä¸­ | 1æ—¥ |
| 6 | **UX** | Streamlitè©•ä¾¡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ | çµæœã®å¯è¦–åŒ– | ä¸­ | 2æ—¥ |
| 7 | **æ©Ÿèƒ½** | ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«å¯¾å¿œ | Webæ¤œç´¢ã€è¨ˆç®—ãƒ„ãƒ¼ãƒ«è¿½åŠ  | ä½ | 3æ—¥ |
| 8 | **æ©Ÿèƒ½** | ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†æ”¹å–„ | Redisæ´»ç”¨ | ä½ | 2æ—¥ |

### 6.2 ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³

```
Phase 3.1 (1é€±é–“)
â”œâ”€â”€ è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å®Ÿè£…
â”œâ”€â”€ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹20ä»¶ä½œæˆ
â””â”€â”€ åˆå›ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¸¬å®š

Phase 3.2 (1é€±é–“)
â”œâ”€â”€ CI/CDçµ±åˆ
â”œâ”€â”€ ãƒ­ã‚®ãƒ³ã‚°ãƒ»å‹ãƒ’ãƒ³ãƒˆæ”¹å–„
â””â”€â”€ Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Phase 3.3 (2é€±é–“)
â”œâ”€â”€ ãƒãƒ«ãƒãƒ„ãƒ¼ãƒ«å¯¾å¿œ
â”œâ”€â”€ æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
â””â”€â”€ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™ãƒ»å…¬é–‹æº–å‚™
```

### 6.3 è©•ä¾¡ã‚µã‚¤ã‚¯ãƒ«

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ â”‚
â”‚   æ¸¬å®š      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¼±ç‚¹ç‰¹å®š   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ï¼ˆå¤±æ•—åˆ†æï¼‰â”‚              â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
      â”‚                      â”‚
      â–¼                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  æ”¹å–„å®Ÿæ–½   â”‚              â”‚
â”‚ ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆâ”‚              â”‚
â”‚ ãƒ»é–¾å€¤èª¿æ•´  â”‚              â”‚
â”‚ ãƒ»ãƒ‡ãƒ¼ã‚¿è¿½åŠ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
      â”‚                      â”‚
      â–¼                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  å†è©•ä¾¡    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ ï¼ˆåŠ¹æœç¢ºèªï¼‰â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. ä»˜éŒ²

### 7.1 å‚è€ƒãƒªãƒ³ã‚¯

- [Google Gemini Function Calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [ReAct: Synergizing Reasoning and Acting (è«–æ–‡)](https://arxiv.org/abs/2210.03629)

### 7.2 ç’°å¢ƒæ§‹ç¯‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```bash
# 1. Pythonç’°å¢ƒ
python --version  # 3.10+

# 2. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install google-generativeai qdrant-client python-dotenv

# 3. Qdrantèµ·å‹•ï¼ˆDockerï¼‰
docker-compose up -d qdrant

# 4. ç’°å¢ƒå¤‰æ•°è¨­å®š
cp .env.example .env
# GEMINI_API_KEY, QDRANT_HOST, QDRANT_PORT ã‚’è¨­å®š

# 5. å‹•ä½œç¢ºèª
python agent_main.py
```

### 7.3 ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦

| å•é¡Œ | åŸå›  | å¯¾å‡¦ |
|------|------|------|
| Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼ | DockerãŒèµ·å‹•ã—ã¦ã„ãªã„ | `docker-compose up -d` |
| API Key ã‚¨ãƒ©ãƒ¼ | ç’°å¢ƒå¤‰æ•°æœªè¨­å®š | `.env` ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª |
| æ¤œç´¢çµæœãªã— | ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒç©º | ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ |
| ã‚¹ã‚³ã‚¢ãŒå¸¸ã«ä½ã„ | é–¾å€¤ãŒé«˜ã™ãã‚‹ | `RAG_SCORE_THRESHOLD` èª¿æ•´ |

---

**Document Version:** 1.0
**Last Updated:** 2025/12/05
**Author:** Claude (Anthropic)