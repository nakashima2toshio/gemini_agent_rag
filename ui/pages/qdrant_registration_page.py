#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
qdrant_registration_page.py - Qdrantç™»éŒ²ãƒšãƒ¼ã‚¸
==============================================
Q/Aãƒ‡ãƒ¼ã‚¿ã®Qdrantã¸ã®ç™»éŒ²æ©Ÿèƒ½

æ©Ÿèƒ½:
- CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Qdrantã¸ã®ç™»éŒ²
- ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆä½œæˆãƒ»å‰Šé™¤ï¼‰
- åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
"""

import logging
from datetime import datetime
from pathlib import Path

import pandas as pd
import streamlit as st
from qdrant_client import QdrantClient

# ã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.qdrant_service import (
    get_collection_stats,
    get_all_collections,
    delete_all_collections,
    load_csv_for_qdrant,
    build_inputs_for_embedding,
    embed_texts_for_qdrant,
    create_or_recreate_collection_for_qdrant,
    build_points_for_qdrant,
    upsert_points_to_qdrant,
    merge_collections,
)

logger = logging.getLogger(__name__)


def show_qdrant_registration_page():
    """ç”»é¢3: Q/Aãƒšã‚¢ãƒ‡ãƒ¼ã‚¿Qdrantç™»éŒ²"""
    st.title("ğŸ—„ï¸ Q/Aãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ãƒ»Qdrantç™»éŒ²")
    st.caption("qa_output/*.csvã®ãƒ‡ãƒ¼ã‚¿ã‚’Qdrantãƒ™ã‚¯ãƒˆãƒ«DBã«ç™»éŒ²")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ Qdrantè¨­å®š")

        qdrant_url = st.text_input(
            "Qdrant URL", value="http://localhost:6333", help="Qdrantã‚µãƒ¼ãƒãƒ¼ã®URL"
        )

        st.divider()
        st.header("ğŸ“‹ æ“ä½œãƒ¢ãƒ¼ãƒ‰")

        operation_mode = st.radio(
            "æ“ä½œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
            options=["all_collections", "individual_csv", "collection_merge"],
            format_func=lambda x: {
                "all_collections": "ğŸ“Š å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ“ä½œ",
                "individual_csv": "ğŸ“„ å€‹åˆ¥CSVæ“ä½œ",
                "collection_merge": "ğŸ”— ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ",
            }[x],
            key="qdrant_operation_mode",
        )

        st.divider()

        # ãƒ¢ãƒ¼ãƒ‰åˆ¥è¨­å®š
        if operation_mode == "individual_csv":
            st.subheader("ğŸ“„ CSVè¨­å®š")

            # qa_output/*.csvãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
            qa_output_dir = Path("qa_output")
            if qa_output_dir.exists():
                csv_files = sorted(qa_output_dir.glob("*.csv"))
                csv_options = [f.name for f in csv_files]
            else:
                csv_options = []

            if csv_options:
                selected_csv = st.selectbox(
                    "ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ",
                    options=csv_options,
                    help="ç™»éŒ²ã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
                )

                # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’è‡ªå‹•ç”Ÿæˆï¼ˆã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰
                default_collection = f"qa_{Path(selected_csv).stem}"
                collection_name = st.text_input(
                    "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å",
                    value=default_collection,
                    help="Qdrantã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å",
                )

                recreate_collection = st.checkbox(
                    "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤",
                    value=True,
                    help="æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆ",
                )

                include_answer = st.checkbox(
                    "answerã‚’å«ã‚ã‚‹", value=True, help="åŸ‹ã‚è¾¼ã¿ç”Ÿæˆæ™‚ã«answerã‚‚å«ã‚ã‚‹"
                )

                data_limit = st.number_input(
                    "ãƒ‡ãƒ¼ã‚¿ä»¶æ•°åˆ¶é™",
                    min_value=0,
                    max_value=100000,
                    value=0,
                    step=100,
                    help="0=ç„¡åˆ¶é™",
                )
            else:
                st.warning("qa_output/ãƒ•ã‚©ãƒ«ãƒ€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                selected_csv = None
                collection_name = None
                recreate_collection = False
                include_answer = False
                data_limit = 0

    # Qdrantæ¥ç¶šç¢ºèª
    st.subheader("ğŸ“¡ Qdrantæ¥ç¶šçŠ¶æ…‹")

    try:
        client = QdrantClient(url=qdrant_url, timeout=30)
        client.get_collections()
        st.success(f"âœ… Qdrantæ¥ç¶šæˆåŠŸ: {qdrant_url}")
        qdrant_connected = True
    except Exception as e:
        st.error(f"âŒ Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        st.warning("QdrantãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code("docker run -p 6333:6333 qdrant/qdrant", language="bash")
        qdrant_connected = False
        client = None

    st.divider()

    # ãƒ¢ãƒ¼ãƒ‰åˆ¥ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if operation_mode == "all_collections":
        # ===================================================================
        # å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ“ä½œãƒ¢ãƒ¼ãƒ‰
        # ===================================================================
        st.subheader("ğŸ“Š å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§")

        if qdrant_connected and client:
            try:
                collections = get_all_collections(client)

                if collections:
                    total_points = sum(c["points_count"] for c in collections)

                    col_metric1, col_metric2 = st.columns(2)
                    with col_metric1:
                        st.metric("ç·ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°", f"{len(collections)} å€‹")
                    with col_metric2:
                        st.metric("ç·ãƒã‚¤ãƒ³ãƒˆæ•°", f"{total_points:,} ä»¶")

                    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§è¡¨
                    df_collections = pd.DataFrame(collections)
                    df_collections = df_collections.sort_values(
                        "points_count", ascending=False
                    )

                    st.dataframe(
                        df_collections,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "name": st.column_config.TextColumn(
                                "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å", width="medium"
                            ),
                            "points_count": st.column_config.NumberColumn(
                                "ãƒã‚¤ãƒ³ãƒˆæ•°", format="%d"
                            ),
                            "status": st.column_config.TextColumn(
                                "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", width="small"
                            ),
                        },
                    )

                    st.divider()

                    # å±é™ºãªæ“ä½œã‚»ã‚¯ã‚·ãƒ§ãƒ³
                    st.subheader("âš ï¸ å±é™ºãªæ“ä½œ")

                    col_btn1, col_btn2 = st.columns(2)

                    with col_btn1:
                        if st.button(
                            "ğŸ—‘ï¸ å…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤",
                            type="secondary",
                            use_container_width=True,
                        ):
                            st.session_state["confirm_delete_all"] = True

                    with col_btn2:
                        if st.button(
                            "ğŸ“Š è©³ç´°çµ±è¨ˆè¡¨ç¤º", type="primary", use_container_width=True
                        ):
                            st.session_state["show_detailed_stats"] = True

                    # å‰Šé™¤ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°
                    if st.session_state.get("confirm_delete_all", False):
                        st.warning("âš ï¸ **è­¦å‘Šï¼šå…¨ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å‰Šé™¤**")
                        st.error(
                            f"**{len(collections)}å€‹**ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆåˆè¨ˆ**{total_points:,}ãƒã‚¤ãƒ³ãƒˆ**ï¼‰ãŒå®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã™ã€‚"
                        )
                        st.error("ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ï¼")

                        col_confirm1, col_confirm2 = st.columns(2)

                        with col_confirm1:
                            if st.button(
                                "âœ… å‰Šé™¤ã‚’å®Ÿè¡Œ",
                                type="primary",
                                use_container_width=True,
                            ):
                                with st.spinner("å‰Šé™¤ä¸­..."):
                                    deleted = delete_all_collections(client)
                                    st.success(
                                        f"âœ… {deleted}å€‹ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
                                    )
                                    st.session_state["confirm_delete_all"] = False
                                    st.rerun()

                        with col_confirm2:
                            if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                                st.session_state["confirm_delete_all"] = False
                                st.rerun()

                    # è©³ç´°çµ±è¨ˆè¡¨ç¤º
                    if st.session_state.get("show_detailed_stats", False):
                        st.divider()
                        st.subheader("ğŸ“Š è©³ç´°çµ±è¨ˆæƒ…å ±")

                        for col_info in collections:
                            with st.expander(
                                f"ğŸ“¦ {col_info['name']} ({col_info['points_count']:,} ãƒã‚¤ãƒ³ãƒˆ)"
                            ):
                                try:
                                    stats = get_collection_stats(
                                        client, col_info["name"]
                                    )
                                    if stats:
                                        st.json(stats)
                                    else:
                                        st.warning("çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                                except Exception as e:
                                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

                        if st.button("é–‰ã˜ã‚‹"):
                            st.session_state["show_detailed_stats"] = False
                            st.rerun()

                else:
                    st.info("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ã¾ã›ã‚“")

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.warning("Qdrantã«æ¥ç¶šã§ãã¦ã„ã¾ã›ã‚“")

    elif operation_mode == "individual_csv":
        # ===================================================================
        # å€‹åˆ¥CSVæ“ä½œãƒ¢ãƒ¼ãƒ‰
        # ===================================================================
        st.subheader("ğŸ“„ CSVç™»éŒ²è¨­å®š")

        if not csv_options:
            st.warning("qa_output/ãƒ•ã‚©ãƒ«ãƒ€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            st.info("å…ˆã«ã€ŒQ/Aç”Ÿæˆã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ãã ã•ã„")
            return

        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        csv_path = qa_output_dir / selected_csv
        file_size = csv_path.stat().st_size
        if file_size < 1024:
            size_str = f"{file_size} B"
        elif file_size < 1024 * 1024:
            size_str = f"{file_size / 1024:.1f} KB"
        else:
            size_str = f"{file_size / (1024 * 1024):.1f} MB"

        col_info1, col_info2 = st.columns(2)
        with col_info1:
            st.info(f"""
**ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±**
- ãƒ•ã‚¡ã‚¤ãƒ«å: {selected_csv}
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {size_str}
- ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å: {collection_name}
            """)

        with col_info2:
            st.info(f"""
**ç™»éŒ²è¨­å®š**
- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å‰Šé™¤: {"ã¯ã„" if recreate_collection else "ã„ã„ãˆ"}
- answerã‚’å«ã‚ã‚‹: {"ã¯ã„" if include_answer else "ã„ã„ãˆ"}
- ãƒ‡ãƒ¼ã‚¿ä»¶æ•°åˆ¶é™: {data_limit if data_limit > 0 else "ç„¡åˆ¶é™"}
            """)

        # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®3ä»¶ï¼‰"):
            try:
                df_preview = pd.read_csv(csv_path, nrows=3)
                st.dataframe(df_preview, use_container_width=True)
            except Exception as e:
                st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

        st.divider()

        # ç™»éŒ²ãƒœã‚¿ãƒ³
        run_registration = st.button(
            "ğŸš€ Qdrantã«ç™»éŒ²",
            type="primary",
            use_container_width=True,
            disabled=not qdrant_connected,
        )

        # ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢
        st.subheader("ğŸ“œ å‡¦ç†ãƒ­ã‚°")
        log_container = st.container()

        if "qdrant_logs" not in st.session_state:
            st.session_state["qdrant_logs"] = []

        def add_log(message: str):
            """ãƒ­ã‚°ã‚’è¿½åŠ """
            timestamp = datetime.now().strftime("%H:%M:%S")
            st.session_state["qdrant_logs"].append(f"[{timestamp}] {message}")

        # ç™»éŒ²å‡¦ç†å®Ÿè¡Œ
        if run_registration:
            st.session_state["qdrant_logs"] = []  # ãƒ­ã‚°ã‚¯ãƒªã‚¢
            add_log(f"ğŸš€ ç™»éŒ²å‡¦ç†é–‹å§‹: {selected_csv}")

            try:
                # ã‚¹ãƒ†ãƒƒãƒ—1: CSVãƒ­ãƒ¼ãƒ‰
                with st.spinner("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­..."):
                    add_log(f"ğŸ“ CSVèª­ã¿è¾¼ã¿: {csv_path}")
                    df = load_csv_for_qdrant(str(csv_path), limit=data_limit)
                    add_log(f"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
                with st.spinner("ğŸ—„ï¸ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™ä¸­..."):
                    add_log(f"ğŸ—„ï¸ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™: {collection_name}")
                    create_or_recreate_collection_for_qdrant(
                        client, collection_name, recreate_collection
                    )
                    add_log("âœ… ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™å®Œäº†")

                # ã‚¹ãƒ†ãƒƒãƒ—3: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
                with st.spinner("ğŸ”¢ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­..."):
                    add_log("ğŸ”¢ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆé–‹å§‹")
                    texts = build_inputs_for_embedding(df, include_answer)
                    vectors = embed_texts_for_qdrant(
                        texts, model="gemini-embedding-001"
                    )
                    add_log(f"âœ… {len(vectors)} ä»¶ã®åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰
                with st.spinner("ğŸ“¦ ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ä¸­..."):
                    add_log("ğŸ“¦ Qdrantãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ä¸­")
                    # ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’æ¨å®š
                    if "cc_news" in selected_csv.lower():
                        domain = "cc_news"
                    elif "livedoor" in selected_csv.lower():
                        domain = "livedoor"
                    else:
                        domain = "custom"

                    points = build_points_for_qdrant(df, vectors, domain, selected_csv)
                    add_log(f"âœ… {len(points)} å€‹ã®ãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ")

                # ã‚¹ãƒ†ãƒƒãƒ—5: Qdrantã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
                with st.spinner("â¬†ï¸ Qdrantã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­..."):
                    add_log("â¬†ï¸ Qdrantã«ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­")
                    count = upsert_points_to_qdrant(client, collection_name, points)
                    add_log(f"âœ… {count} ä»¶ã‚’Qdrantã«ç™»éŒ²ã—ã¾ã—ãŸ")

                # å®Œäº†
                add_log("ğŸ‰ å…¨å‡¦ç†å®Œäº†ï¼")
                st.success(f"âœ… {count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’Qdrantã«ç™»éŒ²ã—ã¾ã—ãŸ")

                # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                try:
                    stats = get_collection_stats(client, collection_name)
                    if stats:
                        st.divider()
                        st.subheader("ğŸ“Š ç™»éŒ²çµæœ")
                        st.json(stats)
                except Exception as e:
                    logger.warning(f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

            except Exception as e:
                add_log(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

        # ãƒ­ã‚°è¡¨ç¤º
        with log_container:
            if st.session_state["qdrant_logs"]:
                log_text = "\n".join(st.session_state["qdrant_logs"])
                st.text_area("å‡¦ç†ãƒ­ã‚°", value=log_text, height=300, disabled=True)
            else:
                st.info("ç™»éŒ²å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹ã¨ã“ã“ã«ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")

    else:
        # ===================================================================
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆãƒ¢ãƒ¼ãƒ‰
        # ===================================================================
        st.subheader("ğŸ”— ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ")
        st.caption("è¤‡æ•°ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ã€1ã¤ã®æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«çµ±åˆã—ã¾ã™")

        if not qdrant_connected or not client:
            st.warning("Qdrantã«æ¥ç¶šã§ãã¦ã„ã¾ã›ã‚“")
            return

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—
        try:
            collections = get_all_collections(client)
        except Exception as e:
            st.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return

        if not collections:
            st.info("çµ±åˆå¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        if len(collections) < 2:
            st.warning("çµ±åˆã«ã¯2ã¤ä»¥ä¸Šã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå¿…è¦ã§ã™")
            return

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠUI
        st.markdown("### çµ±åˆå¯¾è±¡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ")
        st.caption("çµ±åˆã™ã‚‹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’2ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„")

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
        collection_names = [c["name"] for c in collections]
        collection_info_map = {c["name"]: c for c in collections}

        # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§è¤‡æ•°é¸æŠ
        selected_collections = []
        selected_total_points = 0

        for col_info in collections:
            col_name = col_info["name"]
            points_count = col_info["points_count"]

            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤ºï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¨ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’è¡¨ç¤ºï¼‰
            is_selected = st.checkbox(
                f"{col_name} ({points_count:,} ãƒã‚¤ãƒ³ãƒˆ)",
                value=False,
                key=f"merge_checkbox_{col_name}",
            )

            if is_selected:
                selected_collections.append(col_name)
                selected_total_points += points_count

        # é¸æŠã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚µãƒãƒªãƒ¼
        if selected_collections:
            st.divider()
            st.markdown("#### é¸æŠã•ã‚ŒãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³")
            st.success(f"**{len(selected_collections)}** ä»¶é¸æŠä¸­ / çµ±åˆå¾Œã®äºˆæƒ³ãƒã‚¤ãƒ³ãƒˆæ•°: **{selected_total_points:,}** ä»¶")

        st.divider()

        # çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã®è¨­å®š
        st.markdown("### çµ±åˆå…ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆåã‚’ç”Ÿæˆ
        if selected_collections:
            default_merge_name = f"integration_{selected_collections[0]}"
        else:
            default_merge_name = "integration_"

        merge_collection_name = st.text_input(
            "æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å",
            value=default_merge_name,
            help="çµ±åˆå…ˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            key="merge_collection_name_input",
        )

        # åå‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        name_exists = merge_collection_name in collection_names
        if name_exists:
            st.warning(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{merge_collection_name}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚")

        recreate_merge = st.checkbox(
            "æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆ",
            value=True,
            help="åŒåã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å‰Šé™¤ã—ã¦æ–°è¦ä½œæˆã—ã¾ã™",
            key="merge_recreate_checkbox",
        )

        st.divider()

        # çµ±åˆå®Ÿè¡Œãƒœã‚¿ãƒ³
        can_merge = len(selected_collections) >= 2 and merge_collection_name.strip()

        run_merge = st.button(
            "ğŸ”— ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’çµ±åˆ",
            type="primary",
            use_container_width=True,
            disabled=not can_merge,
        )

        if not can_merge:
            if len(selected_collections) < 2:
                st.info("çµ±åˆã«ã¯2ã¤ä»¥ä¸Šã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„")
            elif not merge_collection_name.strip():
                st.info("çµ±åˆå…ˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        # ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢
        st.subheader("ğŸ“œ å‡¦ç†ãƒ­ã‚°")
        merge_log_container = st.container()

        if "merge_logs" not in st.session_state:
            st.session_state["merge_logs"] = []

        def add_merge_log(message: str):
            """çµ±åˆãƒ­ã‚°ã‚’è¿½åŠ """
            timestamp = datetime.now().strftime("%H:%M:%S")
            st.session_state["merge_logs"].append(f"[{timestamp}] {message}")

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
        progress_placeholder = st.empty()
        status_placeholder = st.empty()

        # çµ±åˆå‡¦ç†å®Ÿè¡Œ
        if run_merge:
            st.session_state["merge_logs"] = []  # ãƒ­ã‚°ã‚¯ãƒªã‚¢
            add_merge_log(f"ğŸ”— çµ±åˆå‡¦ç†é–‹å§‹")
            add_merge_log(f"çµ±åˆå…ƒ: {', '.join(selected_collections)}")
            add_merge_log(f"çµ±åˆå…ˆ: {merge_collection_name}")

            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤º
            progress_bar = progress_placeholder.progress(0)

            def progress_callback(message: str, current: int, total: int):
                """é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
                add_merge_log(message)
                if total > 0:
                    progress_bar.progress(current / total)
                status_placeholder.text(message)

            try:
                # çµ±åˆå‡¦ç†ã‚’å®Ÿè¡Œ
                result = merge_collections(
                    client=client,
                    source_collections=selected_collections,
                    target_collection=merge_collection_name,
                    recreate=recreate_merge,
                    progress_callback=progress_callback,
                )

                if result["success"]:
                    add_merge_log("ğŸ‰ çµ±åˆå‡¦ç†å®Œäº†ï¼")

                    # å„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã®å–å¾—ä»¶æ•°ã‚’ãƒ­ã‚°
                    for src_name, count in result["points_per_collection"].items():
                        add_merge_log(f"  - {src_name}: {count:,} ä»¶")

                    add_merge_log(f"åˆè¨ˆ: {result['total_points']:,} ä»¶")

                    st.success(
                        f"âœ… {result['total_points']:,}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ '{merge_collection_name}' ã«çµ±åˆã—ã¾ã—ãŸ"
                    )

                    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                    try:
                        stats = get_collection_stats(client, merge_collection_name)
                        if stats:
                            st.divider()
                            st.subheader("ğŸ“Š çµ±åˆçµæœ")
                            st.json(stats)
                    except Exception as e:
                        logger.warning(f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

                else:
                    add_merge_log(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
                    st.error(f"çµ±åˆã‚¨ãƒ©ãƒ¼: {result['error']}")

            except Exception as e:
                add_merge_log(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                logger.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")

            finally:
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’ã‚¯ãƒªã‚¢
                progress_placeholder.empty()
                status_placeholder.empty()

        # ãƒ­ã‚°è¡¨ç¤º
        with merge_log_container:
            if st.session_state["merge_logs"]:
                log_text = "\n".join(st.session_state["merge_logs"])
                st.text_area("å‡¦ç†ãƒ­ã‚°", value=log_text, height=300, disabled=True)
            else:
                st.info("çµ±åˆå‡¦ç†ã‚’é–‹å§‹ã™ã‚‹ã¨ã“ã“ã«ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")