#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
qdrant_search_page.py - Qdrantæ¤œç´¢ãƒšãƒ¼ã‚¸
========================================
Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ãŸæ„å‘³æ¤œç´¢

æ©Ÿèƒ½:
- ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢
- åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
- AIå¿œç­”ç”Ÿæˆ
"""

import warnings
import pandas as pd
import streamlit as st
from helper_llm import create_llm_client
from qdrant_client import QdrantClient

# ã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.qdrant_service import (
    QdrantDataFetcher,
    embed_query_for_search,
    COLLECTION_EMBEDDINGS_SEARCH,
    COLLECTION_CSV_MAPPING,
)
from services.file_service import load_source_qa_data


def show_qdrant_search_page():
    """ç”»é¢5: Qdrantæ¤œç´¢"""
    st.title("ğŸ” Qdrantæ¤œç´¢")
    st.caption("Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ãŸæ„å‘³æ¤œç´¢")

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œè¡¨ã‚’è¡¨ç¤º
    st.subheader("ğŸ“Š ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œ")
    mapping_data = []
    for collection, csv_file in COLLECTION_CSV_MAPPING.items():
        mapping_data.append(
            {
                "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å": collection,
                "CSVãƒ•ã‚¡ã‚¤ãƒ«": csv_file,
                "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹": f"qa_output/{csv_file}",
            }
        )
    mapping_df = pd.DataFrame(mapping_data)
    st.table(mapping_df)
    st.divider()

    # Qdrantæ¥ç¶šç¢ºèª
    qdrant_url = "http://localhost:6333"

    # åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—
    available_collections = []
    try:
        temp_client = QdrantClient(url=qdrant_url)
        collections_response = temp_client.get_collections()
        available_collections = [col.name for col in collections_response.collections]
    except Exception:
        st.error(f"âŒ Qdrantã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“: {qdrant_url}")
        st.warning("Qdrantã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        st.code("python server.py", language="bash")
        st.caption("ã¾ãŸã¯")
        st.code("docker run -p 6333:6333 qdrant/qdrant", language="bash")
        return

    if not available_collections:
        st.warning("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
        st.info("å…ˆã«ã€ŒQdrantç™»éŒ²ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„")
        return

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šæ¤œç´¢è¨­å®š
    with st.sidebar:
        st.header("ğŸ”§ æ¤œç´¢è¨­å®š")

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ
        collection = st.selectbox(
            "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
            options=available_collections,
            help="æ¤œç´¢å¯¾è±¡ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ",
        )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
        if collection in COLLECTION_EMBEDDINGS_SEARCH:
            col_info = COLLECTION_EMBEDDINGS_SEARCH[collection]
            st.info(f"ğŸ“Š {col_info['model']} ({col_info['dims']}æ¬¡å…ƒ)")

        # Top-Kè¨­å®š
        topk = st.slider(
            "æ¤œç´¢çµæœæ•°ï¼ˆTop-Kï¼‰", min_value=1, max_value=20, value=5, step=1
        )

        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        debug_mode = st.checkbox("ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰", value=False)

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "search_query" not in st.session_state:
        st.session_state.search_query = ""

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.expander("ğŸ“‹ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
        # QdrantDataFetcherã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            client = QdrantClient(url=qdrant_url)
            data_fetcher = QdrantDataFetcher(client)

            # fetch_collection_source_infoã‚’ä½¿ç”¨ã—ã¦ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
            source_info = data_fetcher.fetch_collection_source_info(collection)

            if "error" not in source_info:
                sources = source_info.get("sources", {})

                if sources:
                    st.caption(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: **{collection}**")

                    # å„ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã‚’ä½œæˆ
                    for source, stats in sorted(sources.items()):
                        with st.expander(f"ğŸ“„ {source}", expanded=False):
                            st.markdown(
                                f"- æ¨å®šãƒ‡ãƒ¼ã‚¿æ•°: {stats['estimated_total']:,}ä»¶ ({stats['percentage']:.1f}%)"
                            )
                            st.markdown(f"- ç”Ÿæˆæ–¹æ³•: `{stats['method']}`")
                            st.markdown(f"- ãƒ‰ãƒ¡ã‚¤ãƒ³: `{stats['domain']}`")

                            # question, answerãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
                            df_qa = load_source_qa_data(source, num_rows=20)
                            if df_qa is not None:
                                st.dataframe(
                                    df_qa, use_container_width=True, hide_index=True
                                )
                            else:
                                st.info(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“: qa_output/{source}")
                else:
                    st.info("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {source_info['error']}")
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")

    st.divider()

    # æ¤œç´¢å…¥åŠ›
    st.subheader("ğŸ” æ¤œç´¢")
    query = st.text_input(
        "æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        value=st.session_state.search_query,
        placeholder="æ¤œç´¢ã—ãŸã„è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
    )

    col_search, col_clear = st.columns([4, 1])
    with col_search:
        do_search = st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary", use_container_width=True)
    with col_clear:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.search_query = ""
            st.rerun()

    # æ¤œç´¢å®Ÿè¡Œ
    if do_search and query.strip():
        try:
            client = QdrantClient(url=qdrant_url)

            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã—ãŸåŸ‹ã‚è¾¼ã¿è¨­å®šã‚’å–å¾—
            collection_config = COLLECTION_EMBEDDINGS_SEARCH.get(
                collection, {"model": "gemini-embedding-001", "dims": 3072}
            )
            embedding_model = collection_config["model"]
            embedding_dims = collection_config.get("dims")

            if debug_mode:
                st.info(f"ğŸ” ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {embedding_model} ({embedding_dims}æ¬¡å…ƒ)")

            # ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
            with st.spinner("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­..."):
                qvec = embed_query_for_search(query, embedding_model, embedding_dims)
                if debug_mode:
                    st.success(f"âœ… {len(qvec)}æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

            # Qdrantã§æ¤œç´¢
            with st.spinner("æ¤œç´¢ä¸­..."):
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore", DeprecationWarning)
                    hits = client.search(
                        collection_name=collection, query_vector=qvec, limit=topk
                    )

            # æ¤œç´¢çµæœã‚’è¡¨ç¤º
            st.divider()
            st.subheader(f"ğŸ“Š æ¤œç´¢çµæœ (Top {len(hits)})")

            if not hits:
                st.warning("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return

            # çµæœã‚’DataFrameã«å¤‰æ›
            rows = []
            for h in hits:
                row_data = {
                    "ã‚¹ã‚³ã‚¢": f"{h.score:.4f}",
                    "è³ªå•": h.payload.get("question", "N/A") if h.payload else "N/A",
                    "å›ç­”": h.payload.get("answer", "N/A") if h.payload else "N/A",
                    "ã‚½ãƒ¼ã‚¹": h.payload.get("source", "N/A") if h.payload else "N/A",
                }
                rows.append(row_data)

            df_results = pd.DataFrame(rows)
            st.dataframe(df_results, use_container_width=True, hide_index=True)

            # æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœã‚’è©³ç´°è¡¨ç¤º
            if hits:
                best_hit = hits[0]
                st.divider()
                st.subheader("ğŸ† æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœ")

                col1, col2 = st.columns([1, 3])
                with col1:
                    st.metric("ã‚¹ã‚³ã‚¢", f"{best_hit.score:.4f}")
                with col2:
                    if best_hit.payload:
                        source = best_hit.payload.get("source", "N/A")
                        st.caption(f"ã‚½ãƒ¼ã‚¹: {source}")

                if best_hit.payload:
                    question = best_hit.payload.get("question", "")
                    answer = best_hit.payload.get("answer", "")

                    st.markdown("**è³ªå•:**")
                    st.info(question)

                    st.markdown("**å›ç­”:**")
                    st.success(answer)

                    # Geminiã«ã‚ˆã‚‹æ—¥æœ¬èªå¿œç­”ç”Ÿæˆ
                    st.divider()
                    st.subheader("ğŸ§  AIå¿œç­”ï¼ˆGeminiï¼‰")

                    qa_prompt = (
                        "ä»¥ä¸‹ã®æ¤œç´¢çµæœã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¸ã¾ãˆã¦ã€æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
                        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{query}\n\n"
                        f"æ¤œç´¢çµæœã®ã‚¹ã‚³ã‚¢: {best_hit.score:.4f}\n"
                        f"æ¤œç´¢çµæœã®è³ªå•: {question}\n"
                        f"æ¤œç´¢çµæœã®å›ç­”: {answer}\n"
                    )

                    with st.expander("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°", expanded=False):
                        st.code(qa_prompt)

                    try:
                        with st.spinner("Gemini AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                            llm_client = create_llm_client(provider="gemini")
                            generated_answer = llm_client.generate_content(
                                prompt=qa_prompt,
                                model="gemini-2.0-flash"
                            )

                        if generated_answer and generated_answer.strip():
                            st.markdown("**AIå¿œç­”:**")
                            st.write(generated_answer)
                        else:
                            st.info("å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    except Exception as gen_err:
                        st.error(f"AIå¿œç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(gen_err)}")
                        if debug_mode:
                            st.exception(gen_err)

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            if debug_mode:
                st.exception(e)

            if "Connection refused" in str(e):
                st.warning("Qdrantã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                st.code("python server.py", language="bash")
            elif "collection" in str(e).lower() and "not found" in str(e).lower():
                st.warning(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                st.info("ã€ŒQdrantç™»éŒ²ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„")